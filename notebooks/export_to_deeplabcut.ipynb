{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7670b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "from zephir.methods import build_annotations\n",
    "from zephir.utils.utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1baab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to Zephir dataset\n",
    "dataset = Path('.')\n",
    "\n",
    "# path to DeepLabCut project directory\n",
    "path_to_dlc_project = Path('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# creating directories for DeepLabCut project\n",
    "# only run this if it does not yet exist\n",
    "Path.mkdir(path_to_dlc_project)\n",
    "Path.mkdir(path_to_dlc_project / 'labeled-data')\n",
    "Path.mkdir(path_to_dlc_project / 'labeled-data' / 'zeir')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metadata = get_metadata(dataset)\n",
    "img_shape = np.array([metadata['shape_x'], metadata['shape_y']])\n",
    "\n",
    "# retrieving Zephir user arguments from checkpoint.pt\n",
    "# edit the dictionary before the next cell as needed\n",
    "args = get_checkpoint(dataset, 'args', verbose=True)\n",
    "# args['--wlid_ref'] = None\n",
    "# args['--n_ref'] = None\n",
    "# update_checkpoint(dataset,{'args': args})\n",
    "\n",
    "# retrieving Zephir variable container from checkpoint.pt\n",
    "# update the values in the container before the next cell as needed\n",
    "container = get_checkpoint(dataset, 'container')\n",
    "# container.update({\n",
    "#     'exclude_self': False,\n",
    "#     'exclusive_prov': None,\n",
    "# })\n",
    "\n",
    "print(f'Variables for build_annotations in container:\\n'\n",
    "      f'\\texclude_self: {container.get(\"exclude_self\")}\\n'\n",
    "      f'\\texclusive_prov: {container.get(\"exclusive_prov\")}\\n'\n",
    "      f'\\tshape_t: {container.get(\"shape_t\")}')\n",
    "\n",
    "args"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# define the frames to use for training DeepLabCut\n",
    "t_list = []\n",
    "# t_list = eval(args['--t_ref']) if args['--t_ref'] else None\n",
    "\n",
    "container, results = build_annotations(\n",
    "    container=container,\n",
    "    annotation=None,\n",
    "    t_ref=t_list,\n",
    "    wlid_ref=eval(args['--wlid_ref']) if args['--wlid_ref'] else None,\n",
    "    n_ref=int(args['--n_ref']) if args['--n_ref'] else None,\n",
    ")\n",
    "\n",
    "annot = np.array(container.get('annot'))\n",
    "shape_n = container.get('shape_n')\n",
    "t_annot = container.get('t_annot')\n",
    "worldline_id = container.get('worldline_id')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_to_dir = path_to_dlc_project / 'labeled-data' / 'zeir'\n",
    "\n",
    "# creates a folder of images as training input\n",
    "img_address_list = []\n",
    "for t in t_annot:\n",
    "    frame = get_slice(dataset, t)\n",
    "    frame = np.transpose(frame[:, 0, ...], (1, 2, 0))\n",
    "    frame = np.append(frame, frame[:, :, 0, None], axis=-1)\n",
    "    address = str(path_to_dir / f'img{t:04}.png')\n",
    "    cv2.imwrite(address, frame)\n",
    "    img_address_list.append(address)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compiling a list of body parts to track\n",
    "# define an explicit list of parts directly, must be in the same order as worldlines\n",
    "# use 'dlc' to import the list of parts from existing DeepLabCut project\n",
    "# use 'zeir' to import the list from worldlines.h5, created in annotator GUI\n",
    "bodyparts = None\n",
    "\n",
    "if type(bodyparts) is list:\n",
    "    pass\n",
    "\n",
    "elif bodyparts == 'dlc':\n",
    "    with open(str(path_to_dlc_project / 'config.yaml'), 'r') as cfg:\n",
    "        config = yaml.safe_load(cfg)\n",
    "    bodyparts = config['bodyparts']\n",
    "\n",
    "elif bodyparts == 'zeir' and (dataset / 'worldlines.h5').is_file():\n",
    "    with h5py.File(dataset / 'worldlines.h5', 'r') as f:\n",
    "        worldlines = pd.DataFrame()\n",
    "        for k in f:\n",
    "            worldlines[k] = f[k]\n",
    "    bodyparts = np.array(worldlines[\"name\"])[worldline_id]\n",
    "\n",
    "else:\n",
    "    bodyparts = [str(w) for w in worldline_id]\n",
    "\n",
    "bodyparts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# compiling the annotations pulled from annotations.h5 to a DeepLabCut-compatible dataframe\n",
    "df = None\n",
    "for i in tqdm(range(shape_n), desc='Exporting annotations', unit='bodypart'):\n",
    "    bodypart = bodyparts[i]\n",
    "    index = pd.MultiIndex.from_product(\n",
    "        [['zeir'], [bodypart], ['x', 'y']],\n",
    "        names=['scorer', 'bodyparts', 'coords']\n",
    "    )\n",
    "\n",
    "    xyz_scaled = (annot[:, i, :2] + 1) / 2 * img_shape\n",
    "    xlist, ylist = xyz_scaled[:, 0], xyz_scaled[:, 1]\n",
    "    _df = pd.DataFrame(\n",
    "        np.vstack([xlist, ylist]).T,\n",
    "        columns=index,\n",
    "        index=img_address_list\n",
    "    )\n",
    "    if df is None:\n",
    "        df = _df\n",
    "    else:\n",
    "        df = pd.concat(\n",
    "            [df, _df],\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "# saving dataframe to file\n",
    "df.to_csv(str(path_to_dir / 'CollectedData_zeir.csv'))\n",
    "df.to_hdf(\n",
    "    str(path_to_dir / 'CollectedData_zeir.h5'),\n",
    "    'df_with_missing',\n",
    "    format='table',\n",
    "    mode='w'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}